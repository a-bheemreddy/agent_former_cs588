{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Process the data and convert it into a pandas DataFrame\n",
    "def create_df(file_name):\n",
    "    data = []\n",
    "    with open(file_name, \"r\") as file:\n",
    "        for line in file:\n",
    "            values = line.strip().split()\n",
    "            frame = float(values[0])\n",
    "            pedestrian_id = float(values[1])\n",
    "            x = float(values[-4])\n",
    "            y = float(values[-2])\n",
    "            data.append([frame, pedestrian_id, x, y])\n",
    "\n",
    "    df = pd.DataFrame(data, columns=[\"frame\", \"pedestrian_id\", \"x\", \"y\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(filename):\n",
    "    # return stats as a dictionary for row in the dataframe\n",
    "    df = create_df(filename)\n",
    "    stats = {}\n",
    "    stats['filename'] = filename\n",
    "    stats['num_frames'] = df['frame'].nunique()\n",
    "    stats['size'] = df.shape[0]\n",
    "    stats['num_pedestrians'] = df['pedestrian_id'].nunique()\n",
    "    xmin, ymin, xmax, ymax = df['x'].min(), df['y'].min(), df['x'].max(), df['y'].max()\n",
    "    stats['xmin'], stats['ymin'], stats['xmax'], stats['ymax'] = xmin, ymin, xmax, ymax\n",
    "    stats['xmean'], stats['ymean'] = df['x'].mean(), df['y'].mean()\n",
    "    stats['xstd'], stats['ystd'] = df['x'].std(), df['y'].std()\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>num_frames</th>\n",
       "      <th>size</th>\n",
       "      <th>num_pedestrians</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>xmean</th>\n",
       "      <th>ymean</th>\n",
       "      <th>xstd</th>\n",
       "      <th>ystd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datasets/eth_ucy/eth/biwi_eth.txt</td>\n",
       "      <td>876</td>\n",
       "      <td>5492</td>\n",
       "      <td>360</td>\n",
       "      <td>-7.690000</td>\n",
       "      <td>-3.170000</td>\n",
       "      <td>14.420000</td>\n",
       "      <td>13.210000</td>\n",
       "      <td>5.263534</td>\n",
       "      <td>5.314636</td>\n",
       "      <td>4.993670</td>\n",
       "      <td>1.897610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datasets/eth_ucy/eth/biwi_hotel_train.txt</td>\n",
       "      <td>934</td>\n",
       "      <td>4946</td>\n",
       "      <td>311</td>\n",
       "      <td>-3.250000</td>\n",
       "      <td>-10.210000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>4.310000</td>\n",
       "      <td>1.346181</td>\n",
       "      <td>-3.168854</td>\n",
       "      <td>1.599533</td>\n",
       "      <td>3.912153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datasets/eth_ucy/eth/biwi_hotel_val.txt</td>\n",
       "      <td>234</td>\n",
       "      <td>1597</td>\n",
       "      <td>81</td>\n",
       "      <td>-2.770000</td>\n",
       "      <td>-10.310000</td>\n",
       "      <td>4.270000</td>\n",
       "      <td>4.110000</td>\n",
       "      <td>1.541046</td>\n",
       "      <td>-2.390858</td>\n",
       "      <td>1.535846</td>\n",
       "      <td>3.810167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datasets/eth_ucy/eth/crowds_zara01_train.txt</td>\n",
       "      <td>697</td>\n",
       "      <td>4307</td>\n",
       "      <td>125</td>\n",
       "      <td>-0.139538</td>\n",
       "      <td>-0.334124</td>\n",
       "      <td>15.480551</td>\n",
       "      <td>12.386444</td>\n",
       "      <td>7.074372</td>\n",
       "      <td>4.937468</td>\n",
       "      <td>4.505082</td>\n",
       "      <td>1.558187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datasets/eth_ucy/eth/crowds_zara01_val.txt</td>\n",
       "      <td>175</td>\n",
       "      <td>846</td>\n",
       "      <td>29</td>\n",
       "      <td>-0.125437</td>\n",
       "      <td>-0.374696</td>\n",
       "      <td>15.224625</td>\n",
       "      <td>8.953084</td>\n",
       "      <td>7.167354</td>\n",
       "      <td>4.693609</td>\n",
       "      <td>4.568171</td>\n",
       "      <td>1.521018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>datasets/eth_ucy/eth/crowds_zara02_train.txt</td>\n",
       "      <td>841</td>\n",
       "      <td>7621</td>\n",
       "      <td>171</td>\n",
       "      <td>-0.357791</td>\n",
       "      <td>-0.273743</td>\n",
       "      <td>15.462872</td>\n",
       "      <td>13.942744</td>\n",
       "      <td>6.731399</td>\n",
       "      <td>5.946267</td>\n",
       "      <td>4.132347</td>\n",
       "      <td>1.597196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>datasets/eth_ucy/eth/crowds_zara02_val.txt</td>\n",
       "      <td>211</td>\n",
       "      <td>2101</td>\n",
       "      <td>47</td>\n",
       "      <td>-0.254873</td>\n",
       "      <td>-0.065393</td>\n",
       "      <td>15.558423</td>\n",
       "      <td>10.109152</td>\n",
       "      <td>6.241661</td>\n",
       "      <td>6.012571</td>\n",
       "      <td>4.041310</td>\n",
       "      <td>1.540637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>datasets/eth_ucy/eth/crowds_zara03_train.txt</td>\n",
       "      <td>603</td>\n",
       "      <td>3708</td>\n",
       "      <td>106</td>\n",
       "      <td>-0.342006</td>\n",
       "      <td>-0.067779</td>\n",
       "      <td>15.563895</td>\n",
       "      <td>12.714362</td>\n",
       "      <td>7.348381</td>\n",
       "      <td>6.107467</td>\n",
       "      <td>4.613071</td>\n",
       "      <td>1.601603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>datasets/eth_ucy/eth/crowds_zara03_val.txt</td>\n",
       "      <td>151</td>\n",
       "      <td>1297</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.256767</td>\n",
       "      <td>0.119330</td>\n",
       "      <td>15.388156</td>\n",
       "      <td>12.112462</td>\n",
       "      <td>6.770736</td>\n",
       "      <td>6.358186</td>\n",
       "      <td>4.302327</td>\n",
       "      <td>1.657028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>datasets/eth_ucy/eth/students001_train.txt</td>\n",
       "      <td>355</td>\n",
       "      <td>18353</td>\n",
       "      <td>375</td>\n",
       "      <td>-0.461971</td>\n",
       "      <td>-0.232216</td>\n",
       "      <td>15.469186</td>\n",
       "      <td>13.891910</td>\n",
       "      <td>8.055184</td>\n",
       "      <td>7.032756</td>\n",
       "      <td>4.024789</td>\n",
       "      <td>3.406763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>datasets/eth_ucy/eth/students001_val.txt</td>\n",
       "      <td>89</td>\n",
       "      <td>3460</td>\n",
       "      <td>96</td>\n",
       "      <td>-0.384941</td>\n",
       "      <td>-0.318372</td>\n",
       "      <td>15.344380</td>\n",
       "      <td>13.841314</td>\n",
       "      <td>8.379548</td>\n",
       "      <td>7.061122</td>\n",
       "      <td>3.854836</td>\n",
       "      <td>3.512601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>datasets/eth_ucy/eth/students003_train.txt</td>\n",
       "      <td>432</td>\n",
       "      <td>15641</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.174686</td>\n",
       "      <td>-0.222192</td>\n",
       "      <td>15.436984</td>\n",
       "      <td>13.737735</td>\n",
       "      <td>8.540992</td>\n",
       "      <td>7.583816</td>\n",
       "      <td>4.322379</td>\n",
       "      <td>2.890706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>datasets/eth_ucy/eth/students003_val.txt</td>\n",
       "      <td>109</td>\n",
       "      <td>2312</td>\n",
       "      <td>92</td>\n",
       "      <td>0.060824</td>\n",
       "      <td>-0.111454</td>\n",
       "      <td>15.337645</td>\n",
       "      <td>13.854201</td>\n",
       "      <td>8.485331</td>\n",
       "      <td>7.896745</td>\n",
       "      <td>4.462531</td>\n",
       "      <td>3.200996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>datasets/eth_ucy/eth/uni_examples_train.txt</td>\n",
       "      <td>587</td>\n",
       "      <td>2266</td>\n",
       "      <td>96</td>\n",
       "      <td>-0.428717</td>\n",
       "      <td>0.032219</td>\n",
       "      <td>15.613144</td>\n",
       "      <td>13.858975</td>\n",
       "      <td>7.350246</td>\n",
       "      <td>8.729563</td>\n",
       "      <td>4.085029</td>\n",
       "      <td>2.324678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>datasets/eth_ucy/eth/uni_examples_val.txt</td>\n",
       "      <td>147</td>\n",
       "      <td>481</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.222672</td>\n",
       "      <td>6.491547</td>\n",
       "      <td>15.596096</td>\n",
       "      <td>13.765897</td>\n",
       "      <td>7.708939</td>\n",
       "      <td>9.843377</td>\n",
       "      <td>4.366483</td>\n",
       "      <td>1.357883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        filename  num_frames   size  \\\n",
       "0              datasets/eth_ucy/eth/biwi_eth.txt         876   5492   \n",
       "1      datasets/eth_ucy/eth/biwi_hotel_train.txt         934   4946   \n",
       "2        datasets/eth_ucy/eth/biwi_hotel_val.txt         234   1597   \n",
       "3   datasets/eth_ucy/eth/crowds_zara01_train.txt         697   4307   \n",
       "4     datasets/eth_ucy/eth/crowds_zara01_val.txt         175    846   \n",
       "5   datasets/eth_ucy/eth/crowds_zara02_train.txt         841   7621   \n",
       "6     datasets/eth_ucy/eth/crowds_zara02_val.txt         211   2101   \n",
       "7   datasets/eth_ucy/eth/crowds_zara03_train.txt         603   3708   \n",
       "8     datasets/eth_ucy/eth/crowds_zara03_val.txt         151   1297   \n",
       "9     datasets/eth_ucy/eth/students001_train.txt         355  18353   \n",
       "10      datasets/eth_ucy/eth/students001_val.txt          89   3460   \n",
       "11    datasets/eth_ucy/eth/students003_train.txt         432  15641   \n",
       "12      datasets/eth_ucy/eth/students003_val.txt         109   2312   \n",
       "13   datasets/eth_ucy/eth/uni_examples_train.txt         587   2266   \n",
       "14     datasets/eth_ucy/eth/uni_examples_val.txt         147    481   \n",
       "\n",
       "    num_pedestrians      xmin       ymin       xmax       ymax     xmean  \\\n",
       "0               360 -7.690000  -3.170000  14.420000  13.210000  5.263534   \n",
       "1               311 -3.250000 -10.210000   4.350000   4.310000  1.346181   \n",
       "2                81 -2.770000 -10.310000   4.270000   4.110000  1.541046   \n",
       "3               125 -0.139538  -0.334124  15.480551  12.386444  7.074372   \n",
       "4                29 -0.125437  -0.374696  15.224625   8.953084  7.167354   \n",
       "5               171 -0.357791  -0.273743  15.462872  13.942744  6.731399   \n",
       "6                47 -0.254873  -0.065393  15.558423  10.109152  6.241661   \n",
       "7               106 -0.342006  -0.067779  15.563895  12.714362  7.348381   \n",
       "8                33 -0.256767   0.119330  15.388156  12.112462  6.770736   \n",
       "9               375 -0.461971  -0.232216  15.469186  13.891910  8.055184   \n",
       "10               96 -0.384941  -0.318372  15.344380  13.841314  8.379548   \n",
       "11              364 -0.174686  -0.222192  15.436984  13.737735  8.540992   \n",
       "12               92  0.060824  -0.111454  15.337645  13.854201  8.485331   \n",
       "13               96 -0.428717   0.032219  15.613144  13.858975  7.350246   \n",
       "14               24 -0.222672   6.491547  15.596096  13.765897  7.708939   \n",
       "\n",
       "       ymean      xstd      ystd  \n",
       "0   5.314636  4.993670  1.897610  \n",
       "1  -3.168854  1.599533  3.912153  \n",
       "2  -2.390858  1.535846  3.810167  \n",
       "3   4.937468  4.505082  1.558187  \n",
       "4   4.693609  4.568171  1.521018  \n",
       "5   5.946267  4.132347  1.597196  \n",
       "6   6.012571  4.041310  1.540637  \n",
       "7   6.107467  4.613071  1.601603  \n",
       "8   6.358186  4.302327  1.657028  \n",
       "9   7.032756  4.024789  3.406763  \n",
       "10  7.061122  3.854836  3.512601  \n",
       "11  7.583816  4.322379  2.890706  \n",
       "12  7.896745  4.462531  3.200996  \n",
       "13  8.729563  4.085029  2.324678  \n",
       "14  9.843377  4.366483  1.357883  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "folder_path = 'datasets/eth_ucy/eth/'\n",
    "# get all txt files in the folder\n",
    "text_files = [f for f in os.listdir(folder_path) if f.endswith('.txt')]\n",
    "file_paths = [os.path.join(folder_path, f) for f in text_files]\n",
    "# file_paths.append('process_vedan.txt')\n",
    "# file_paths.append('')\n",
    "rows = [get_stats(f) for f in file_paths]\n",
    "df = pd.DataFrame(rows)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average training data coordinate is x: 7.279079259848324, y: 5.999566365297577\n"
     ]
    }
   ],
   "source": [
    "# select only rows with filename containing 'train\n",
    "df_train = df[df['filename'].str.contains('train')]\n",
    "df_train_total_x = df_train['xmean'] * df_train['size']\n",
    "df_train_total_y = df_train['ymean'] * df_train['size']\n",
    "average_x = df_train_total_x.sum() / df_train['size'].sum()\n",
    "average_y = df_train_total_y.sum() / df_train['size'].sum()\n",
    "print(f'average training data coordinate is x: {average_x}, y: {average_y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.772715454691877 0.6214587844932091\n",
      "6.775904718152959 0.38748479611372494\n"
     ]
    }
   ],
   "source": [
    "df_our_data = create_df('processed_vedan.txt')\n",
    "our_stats = get_stats('processed_vedan.txt')\n",
    "df_parallel = create_df('processed_parallel_tracking.txt')\n",
    "parallel_stats = get_stats('processed_parallel_tracking.txt')\n",
    "print(parallel_stats['xmean'], parallel_stats['ymean'])\n",
    "print(our_stats['xmean'], our_stats['ymean'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_offset = 1\n",
    "y_offset = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Open the txt file\n",
    "with open(\"tracking_parallel.txt\", \"r\") as file:\n",
    "    csv_reader = csv.reader(file, delimiter=\" \")\n",
    "\n",
    "    # Create a new list to store the filtered rows\n",
    "    filtered_rows = []\n",
    "\n",
    "    # Iterate over each row in the file\n",
    "    for row in csv_reader:\n",
    "        # Only keep the first two pedestrians IDs since there were only\n",
    "        # two pedestrians we kept track of and 1.0 and 2.0 were in all 41 frames\n",
    "        x = float(row[-4])\n",
    "        y = float(row[-2])\n",
    "        row[-4] = str(x + x_offset)\n",
    "        row[-2] = str(y + y_offset)\n",
    "        row[-4], row[-2] = row[-2], row[-4]\n",
    "        filtered_rows.append(row)\n",
    "\n",
    "# Open a new file to write the filtered rows\n",
    "with open(\"processed_parallel_flipped_with_offset.txt\", \"w\") as file:\n",
    "    # Write each filtered row to the new file\n",
    "    for row in filtered_rows:\n",
    "        file.write(\" \".join(row) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pedestrian ID: 1.0\n",
      "Predicted trajectory:\n",
      "[[4.38147711 4.37583055]\n",
      " [4.370184   4.36453745]\n",
      " [4.35889089 4.35324434]\n",
      " [4.34759779 4.34195123]\n",
      " [4.33630468 4.33065813]\n",
      " [4.32501157 4.31936502]\n",
      " [3.02919675 3.01892903]\n",
      " [3.00866131 2.99839358]\n",
      " [2.98812586 2.97785814]\n",
      " [2.96759041 2.95732269]\n",
      " [2.94705497 2.93678725]\n",
      " [2.92651952 2.9162518 ]]\n",
      "\n",
      "Pedestrian ID: 2.0\n",
      "Predicted trajectory:\n",
      "[[3.8467848  3.8841406 ]\n",
      " [3.9214964  3.9588522 ]\n",
      " [3.996208   4.0335638 ]\n",
      " [4.0709196  4.1082754 ]\n",
      " [4.1456312  4.182987  ]\n",
      " [4.2203428  4.2576986 ]\n",
      " [4.00579463 4.00696764]\n",
      " [4.00814064 4.00931365]\n",
      " [4.01048665 4.01165966]\n",
      " [4.01283266 4.01400567]\n",
      " [4.01517867 4.01635168]\n",
      " [4.01752468 4.01869769]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Filter out rows with missing coordinates\n",
    "df = df[(df[\"x\"] != -1.0) & (df[\"y\"] != -1.0)]\n",
    "\n",
    "# Define the constant velocity model function\n",
    "def constant_velocity_model(t, x0, y0, vx, vy):\n",
    "    x = x0 + vx * t\n",
    "    y = y0 + vy * t\n",
    "    # Ensure that the model returns a 1D array representing both x and y\n",
    "    # predictions interleaved, aligning with what curve_fit expects.\n",
    "    return np.hstack((x, y))\n",
    "\n",
    "# Get unique pedestrian IDs\n",
    "pedestrian_ids = df[\"pedestrian_id\"].unique()\n",
    "\n",
    "# Iterate over each pedestrian and make predictions\n",
    "for pedestrian_id in pedestrian_ids:\n",
    "    pedestrian_df = df[df[\"pedestrian_id\"] == pedestrian_id]\n",
    "    \n",
    "    # Extract time steps and positions for the current pedestrian\n",
    "    time_steps = pedestrian_df[\"frame\"].values\n",
    "    positions = pedestrian_df[[\"x\", \"y\"]].values\n",
    "    \n",
    "    # Fit the constant velocity model to the trajectory data\n",
    "    initial_guess = [positions[0, 0], positions[0, 1], 1.0, 1.0]\n",
    "    popt, _ = curve_fit(constant_velocity_model, time_steps, positions.ravel(), p0=initial_guess)\n",
    "    \n",
    "    # Extract the fitted parameters\n",
    "    x0, y0, vx, vy = popt\n",
    "    \n",
    "    # Generate future time steps for prediction\n",
    "    last_time_step = time_steps[-1]\n",
    "    future_time_steps = np.arange(last_time_step + 1, last_time_step + 13)\n",
    "    \n",
    "    # Predict future positions using the constant velocity model\n",
    "    predicted_positions = constant_velocity_model(future_time_steps, x0, y0, vx, vy)\n",
    "    # Reshape back into (N, 2). Makes the output more intuitive for later use when \n",
    "    # you want to plot or work with x and y coordinates separately.\n",
    "    predicted_positions = predicted_positions.reshape(-1, 2)\n",
    "    \n",
    "    # Print the predicted trajectory for the current pedestrian\n",
    "    print(f\"Pedestrian ID: {pedestrian_id}\")\n",
    "    print(\"Predicted trajectory:\")\n",
    "    print(predicted_positions)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted trajectory:\n",
      "[[  5.  14.]\n",
      " [  6.  45.]\n",
      " [  7. 103.]\n",
      " [  8. 196.]\n",
      " [  9. 332.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "# Create sample pedestrian trajectory data\n",
    "trajectory_data = np.array([[0.0, 0.0], [1.0, 2.0], [2.0, 3.0], [3.0, 1.0], [4.0, 2.0]])\n",
    "\n",
    "# Extract time steps and positions from the trajectory data\n",
    "time_steps = trajectory_data[:, 0]\n",
    "x_positions = trajectory_data[:, 1]\n",
    "\n",
    "# Create a cubic spline interpolation function\n",
    "spline = CubicSpline(time_steps, x_positions)\n",
    "\n",
    "# Generate future time steps for prediction\n",
    "num_predictions = 5\n",
    "future_time_steps = np.arange(time_steps[-1] + 1, time_steps[-1] + num_predictions + 1)\n",
    "\n",
    "# Predict future positions using the spline interpolation\n",
    "predicted_positions = spline(future_time_steps)\n",
    "\n",
    "# Print the predicted trajectory\n",
    "print(\"Predicted trajectory:\")\n",
    "print(np.column_stack((future_time_steps, predicted_positions)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
